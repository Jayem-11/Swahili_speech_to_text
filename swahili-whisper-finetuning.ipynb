{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCwaBZ2U2UCx"
   },
   "source": [
    "# Prepare Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T09:58:04.817923Z",
     "iopub.status.busy": "2023-11-14T09:58:04.816992Z",
     "iopub.status.idle": "2023-11-14T09:58:04.864982Z",
     "shell.execute_reply": "2023-11-14T09:58:04.863533Z",
     "shell.execute_reply.started": "2023-11-14T09:58:04.817876Z"
    },
    "id": "kV7BJkD553Ja"
   },
   "outputs": [],
   "source": [
    "# check GPU info\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T09:58:18.122790Z",
     "iopub.status.busy": "2023-11-14T09:58:18.122322Z",
     "iopub.status.idle": "2023-11-14T10:00:21.429385Z",
     "shell.execute_reply": "2023-11-14T10:00:21.427574Z",
     "shell.execute_reply.started": "2023-11-14T09:58:18.122753Z"
    },
    "id": "5f5534ec-9055-4410-ad83-a97484327ef5"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "%%capture\n",
    "!pip install datasets==2.14.1\n",
    "!pip install transformers==4.4.0\n",
    "!pip install torchaudio\n",
    "!pip install librosa\n",
    "!pip install jiwer\n",
    "!pip install evaluate \n",
    "!pip install wandb\n",
    "!pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:21:50.268787Z",
     "iopub.status.busy": "2023-11-13T10:21:50.268350Z",
     "iopub.status.idle": "2023-11-13T10:21:54.953313Z",
     "shell.execute_reply": "2023-11-13T10:21:54.951965Z",
     "shell.execute_reply.started": "2023-11-13T10:21:50.268761Z"
    },
    "id": "6GIWuPHdWEvm"
   },
   "outputs": [],
   "source": [
    "# Weights & Biases (optional)log in\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient() \n",
    "\n",
    "personal_key_for_api = user_secrets.get_secret(\"wandb-key\")\n",
    "\n",
    "! wandb login $personal_key_for_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T10:00:21.432427Z",
     "iopub.status.busy": "2023-11-14T10:00:21.431991Z",
     "iopub.status.idle": "2023-11-14T10:00:21.796542Z",
     "shell.execute_reply": "2023-11-14T10:00:21.795071Z",
     "shell.execute_reply.started": "2023-11-14T10:00:21.432386Z"
    },
    "id": "60a8dbb5-d13e-46c0-9fe8-4293a29b7c7c"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T10:00:21.798782Z",
     "iopub.status.busy": "2023-11-14T10:00:21.798288Z",
     "iopub.status.idle": "2023-11-14T10:00:22.096782Z",
     "shell.execute_reply": "2023-11-14T10:00:22.094806Z",
     "shell.execute_reply.started": "2023-11-14T10:00:21.798737Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "secret_label = \"HFWAV2VEC\"\n",
    "secret_value = UserSecretsClient().get_secret(secret_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-14T10:00:22.100676Z",
     "iopub.status.busy": "2023-11-14T10:00:22.100126Z",
     "iopub.status.idle": "2023-11-14T10:00:22.255710Z",
     "shell.execute_reply": "2023-11-14T10:00:22.254499Z",
     "shell.execute_reply.started": "2023-11-14T10:00:22.100624Z"
    }
   },
   "outputs": [],
   "source": [
    "login(token=secret_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:21:55.713441Z",
     "iopub.status.busy": "2023-11-13T10:21:55.713162Z",
     "iopub.status.idle": "2023-11-13T10:21:55.717446Z",
     "shell.execute_reply": "2023-11-13T10:21:55.716658Z",
     "shell.execute_reply.started": "2023-11-13T10:21:55.713418Z"
    },
    "id": "707bb451-c61b-4b2a-bd3b-6748b535a850"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_name_or_path = \"Jayem-11/whisper-small-swahili-2\"\n",
    "language = \"Swahili\"\n",
    "language_abbr = \"sw\"\n",
    "task = \"transcribe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCjRhrVfDeoG"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "train_5 = load_dataset(\"Jayem-11/mozilla_commonvoice_hackathon_preprocessed_train_batch_5\") \n",
    "train_6 = load_dataset(\"Jayem-11/mozilla_commonvoice_hackathon_preprocessed_train_batch_6\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_voice_train = concatenate_datasets([train_5[\"train\"] , train_6[\"train\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HJLGfk-8A4e"
   },
   "source": [
    "## Prepare Feature Extractor, Tokenizer and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:21:56.760594Z",
     "iopub.status.busy": "2023-11-13T10:21:56.760112Z",
     "iopub.status.idle": "2023-11-13T10:22:02.732224Z",
     "shell.execute_reply": "2023-11-13T10:22:02.730640Z",
     "shell.execute_reply.started": "2023-11-13T10:21:56.760568Z"
    },
    "id": "63df2617-8bf4-41d2-ba71-e3e8107002bf"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(model_name_or_path)\n",
    "tokenizer = WhisperTokenizer.from_pretrained(model_name_or_path, language=language, task=task)\n",
    "processor = WhisperProcessor.from_pretrained(model_name_or_path, language=language, task=task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daf2a825-6d9f-4a23-b145-c37c0039075b"
   },
   "source": [
    "### Load a Pre-Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:22:02.745700Z",
     "iopub.status.busy": "2023-11-13T10:22:02.745297Z",
     "iopub.status.idle": "2023-11-13T10:22:21.175260Z",
     "shell.execute_reply": "2023-11-13T10:22:21.174078Z",
     "shell.execute_reply.started": "2023-11-13T10:22:02.745664Z"
    },
    "id": "e6f5ab46-f817-4c31-b61a-c867f54689ac"
   },
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrMYeN4dHXZ0"
   },
   "source": [
    "Override generation arguments - no tokens are forced as decoder outputs (see [`forced_decoder_ids`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.forced_decoder_ids)), no tokens are suppressed during generation (see [`suppress_tokens`](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.generation_utils.GenerationMixin.generate.suppress_tokens)). Set use_cache to False since we're using gradient checkpointing, and the two are incompatible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:22:21.178095Z",
     "iopub.status.busy": "2023-11-13T10:22:21.177179Z",
     "iopub.status.idle": "2023-11-13T10:22:21.184486Z",
     "shell.execute_reply": "2023-11-13T10:22:21.183103Z",
     "shell.execute_reply.started": "2023-11-13T10:22:21.178054Z"
    },
    "id": "36b44853-395d-476c-8c87-269c44ddafb7"
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:22:21.188137Z",
     "iopub.status.busy": "2023-11-13T10:22:21.187819Z",
     "iopub.status.idle": "2023-11-13T10:22:21.199177Z",
     "shell.execute_reply": "2023-11-13T10:22:21.197945Z",
     "shell.execute_reply.started": "2023-11-13T10:22:21.188103Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_DURATION_IN_SECONDS = 30.0\n",
    "max_input_length = MAX_DURATION_IN_SECONDS * 16000\n",
    "\n",
    "def filter_inputs(input_length):\n",
    "    \"\"\"Filter inputs with zero input length or longer than 30s\"\"\"\n",
    "    return 0 < input_length < max_input_length\n",
    "\n",
    "max_label_length = model.config.max_length\n",
    "\n",
    "def filter_labels(labels_length):\n",
    "    \"\"\"Filter label sequences longer than max length (448)\"\"\"\n",
    "    return labels_length < max_label_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:26:51.470266Z",
     "iopub.status.busy": "2023-11-13T10:26:51.469794Z",
     "iopub.status.idle": "2023-11-13T10:26:59.376469Z",
     "shell.execute_reply": "2023-11-13T10:26:59.375023Z",
     "shell.execute_reply.started": "2023-11-13T10:26:51.470228Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter by audio length\n",
    "common_voice_train = common_voice_train.filter(filter_inputs, input_columns=[\"input_length\"])\n",
    "# filter by label length\n",
    "common_voice_train = common_voice_train.filter(filter_labels, input_columns=[\"labels_length\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-13T10:26:59.379376Z",
     "iopub.status.busy": "2023-11-13T10:26:59.379035Z",
     "iopub.status.idle": "2023-11-13T10:26:59.416429Z",
     "shell.execute_reply": "2023-11-13T10:26:59.415016Z",
     "shell.execute_reply.started": "2023-11-13T10:26:59.379353Z"
    }
   },
   "outputs": [],
   "source": [
    "common_voice_train.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:15.833525Z",
     "iopub.status.busy": "2023-11-07T07:43:15.833123Z",
     "iopub.status.idle": "2023-11-07T07:43:15.887946Z",
     "shell.execute_reply": "2023-11-07T07:43:15.886963Z",
     "shell.execute_reply.started": "2023-11-07T07:43:15.833496Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = common_voice_train.train_test_split(test_size=0.2)[\"train\"]\n",
    "val_dataset  = common_voice_train.train_test_split(test_size=0.2)[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USpS80FTGpv_"
   },
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "39IKVpUAG0LR"
   },
   "source": [
    "### Define a Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:22.530137Z",
     "iopub.status.busy": "2023-11-07T07:43:22.529177Z",
     "iopub.status.idle": "2023-11-07T07:43:22.542200Z",
     "shell.execute_reply": "2023-11-07T07:43:22.541149Z",
     "shell.execute_reply.started": "2023-11-07T07:43:22.530096Z"
    },
    "id": "c15c7a1b-49b9-45c1-a80e-3d7c887793c5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xZhbZNyG5ve"
   },
   "source": [
    "Let's initialise the data collator just defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:23.736386Z",
     "iopub.status.busy": "2023-11-07T07:43:23.735487Z",
     "iopub.status.idle": "2023-11-07T07:43:23.740557Z",
     "shell.execute_reply": "2023-11-07T07:43:23.739424Z",
     "shell.execute_reply.started": "2023-11-07T07:43:23.736351Z"
    },
    "id": "891332b0-47e5-4fec-aff6-a47d67159087"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TP7ggZZG8Mz"
   },
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:29.858484Z",
     "iopub.status.busy": "2023-11-07T07:43:29.857543Z",
     "iopub.status.idle": "2023-11-07T07:43:32.549067Z",
     "shell.execute_reply": "2023-11-07T07:43:32.547856Z",
     "shell.execute_reply.started": "2023-11-07T07:43:29.858447Z"
    },
    "id": "be318294-31c2-4487-94c0-464c8422cf15"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onT_h6GUHBEN"
   },
   "source": [
    "We then simply have to define a function that takes our model \n",
    "predictions and returns the WER metric. This function, called\n",
    "`compute_metrics`, first replaces `-100` with the `pad_token_id`\n",
    "in the `label_ids` (undoing the step we applied in the \n",
    "data collator to ignore padded tokens correctly in the loss).\n",
    "It then decodes the predicted and label ids to strings. Finally,\n",
    "it computes the WER between the predictions and reference labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:32.553008Z",
     "iopub.status.busy": "2023-11-07T07:43:32.550722Z",
     "iopub.status.idle": "2023-11-07T07:43:32.560527Z",
     "shell.execute_reply": "2023-11-07T07:43:32.559586Z",
     "shell.execute_reply.started": "2023-11-07T07:43:32.552964Z"
    },
    "id": "7f64be8b-ce51-4765-a2ca-720ec3dbb9ae"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vp8wyibRH731"
   },
   "source": [
    "### Define the Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:36.102499Z",
     "iopub.status.busy": "2023-11-07T07:43:36.101625Z",
     "iopub.status.idle": "2023-11-07T07:43:36.193702Z",
     "shell.execute_reply": "2023-11-07T07:43:36.192945Z",
     "shell.execute_reply.started": "2023-11-07T07:43:36.102468Z"
    },
    "id": "a2b462f9-cb4e-4fdc-b328-ff99202bf770"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-swahili-3\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=1875,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=20,\n",
    "    report_to=[\"tensorboard\",\"wandb\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:37.617743Z",
     "iopub.status.busy": "2023-11-07T07:43:37.616873Z",
     "iopub.status.idle": "2023-11-07T07:43:42.979650Z",
     "shell.execute_reply": "2023-11-07T07:43:42.978820Z",
     "shell.execute_reply.started": "2023-11-07T07:43:37.617711Z"
    },
    "id": "839f4070-fac6-4d1b-aa6f-73b73e00a42b"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-07T07:43:42.981737Z",
     "iopub.status.busy": "2023-11-07T07:43:42.981374Z",
     "iopub.status.idle": "2023-11-07T07:43:43.114489Z",
     "shell.execute_reply": "2023-11-07T07:43:43.113616Z",
     "shell.execute_reply.started": "2023-11-07T07:43:42.981704Z"
    },
    "id": "58dcd336-6420-4720-80b7-6684b7e83a30"
   },
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-06T14:28:54.675414Z",
     "iopub.status.busy": "2023-11-06T14:28:54.675034Z",
     "iopub.status.idle": "2023-11-06T14:34:16.925029Z",
     "shell.execute_reply": "2023-11-06T14:34:16.923586Z",
     "shell.execute_reply.started": "2023-11-06T14:28:54.675387Z"
    },
    "id": "a455f992-7adf-4863-8cce-89660ac774b6"
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub(\"Jayem-11/whisper-small-swahili-3\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3974671,
     "sourceId": 6963980,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
